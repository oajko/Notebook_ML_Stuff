{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization, Concatenate, Input, Flatten\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "tf.keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of this network: https://arxiv.org/abs/1912.09363... Well at least the feature filtering aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gate(Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.linear = Dense(units)\n",
    "        self.sigmoid = Dense(units, activation=\"sigmoid\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs) * self.sigmoid(inputs)\n",
    "\n",
    "class GRN(Layer):\n",
    "    def __init__(self, units, drop, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.elu = Dense(units, activation= 'elu')\n",
    "        self.linear = Dense(units)\n",
    "        self.dropout = Dropout(drop)\n",
    "        self.gate = Gate(units)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.filter = Dense(units)\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.elu(inputs)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        if inputs.shape[-1] != self.units:\n",
    "            inputs = self.filter(inputs)\n",
    "        x = inputs + self.gate(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSN(Layer):\n",
    "    def __init__(self, units, drop, feat_num, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feat_num = feat_num\n",
    "        self.grn_list = [GRN(units, drop) for _ in range(feat_num)]\n",
    "        self.grn = GRN(units, drop)\n",
    "        self.softmax = Dense(units = feat_num, activation = 'softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        all = self.grn(inputs)\n",
    "        all = tf.expand_dims(self.softmax(all), axis = -1)   \n",
    "        \n",
    "        indi = []\n",
    "        split_list = tf.split(inputs, self.feat_num, axis = -1)\n",
    "        for idx, i in enumerate(split_list):\n",
    "            indi.append(self.grn_list[idx](i))\n",
    "        indi = tf.stack(indi, axis=1)\n",
    "        \n",
    "        outputs = tf.squeeze(tf.matmul(all, indi, transpose_a=True), axis=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Models and base testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate into own GRU layer. And dot product with total GRN.\n",
    "def vsn_mdl(df):\n",
    "    inputs_1 = tf.keras.Input(shape = (df.shape[1],))\n",
    "    x = VSN(16, 0.5, df.shape[1])(inputs_1)\n",
    "    x = VSN(8, 0.5, 16)(x)\n",
    "    output = Dense(units = 1, activation = 'sigmoid')(x)\n",
    "    return tf.keras.Model(inputs_1, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(df):\n",
    "    start = Input(shape = (df.shape[1],))\n",
    "    end = Dense(units = 1, activation = 'sigmoid')(start)\n",
    "    model = tf.keras.Model(start, end)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv').select_dtypes(exclude = object)\n",
    "# df = df.drop('Survived', axis = 1)\n",
    "# y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6719278693199158\n"
     ]
    }
   ],
   "source": [
    "mdl = vsn_mdl(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "history = mdl.fit(x = df.iloc[:, 1:], y = df.Survived, epochs = 30, verbose = 0)\n",
    "print(max(history.history['Accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6009019017219543\n"
     ]
    }
   ],
   "source": [
    "mdl = base_model(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "history = mdl.fit(x = df.iloc[:, 1:], y = df.Survived, epochs = 30, verbose = 0)\n",
    "print(max(history.history['Accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_dnn(df):\n",
    "    start = Input(shape = (df.shape[1],))\n",
    "    x = VSN(64, 0.2, df.shape[1],)(start)\n",
    "    x = VSN(32, 0.2, 64)(x)\n",
    "    x = VSN(16, 0.2, 32)(x)\n",
    "    x = Dense(64, activation = 'relu')(x)\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    end = Dense(units = 1, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(start, end)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_dnn(df):\n",
    "    start = Input(shape = (df.shape[1],))\n",
    "    x = Dense(64, activation = 'relu')(start)\n",
    "    x = Dense(32, activation = 'relu')(x)\n",
    "    end = Dense(units = 1, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(start, end)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6944757699966431\n"
     ]
    }
   ],
   "source": [
    "mdl = variable_dnn(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "history = mdl.fit(x = df.iloc[:, 1:], y = df.Survived, epochs = 30, verbose = 0)\n",
    "print(max(history.history['Accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7080045342445374\n"
     ]
    }
   ],
   "source": [
    "mdl = base_dnn(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "history = mdl.fit(x = df.iloc[:, 1:], y = df.Survived, epochs = 30, verbose = 0)\n",
    "print(max(history.history['Accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization ability using TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6981981981981982"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = vsn_mdl(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "mdl.fit(x = X_train, y = y_train, epochs = 30, verbose = 0)\n",
    "preds = mdl.predict(X_test, verbose = 0)\n",
    "(np.round(preds).flatten() == y_test).sum()/ len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6711711711711712"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = base_model(df.drop('Survived', axis = 1))\n",
    "mdl.compile(loss = 'binary_crossentropy', optimizer = 'SGD', metrics = ['Accuracy'])\n",
    "mdl.fit(x = X_train, y = y_train, epochs = 30, verbose = 0)\n",
    "preds = mdl.predict(X_test, verbose = 0)\n",
    "(np.round(preds).flatten() == y_test).sum()/ len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results above is trained on the titanic dataset. We test variable selection model on three tests. No hidden network (input of (5, 1) -> output (1, )) network, a dnn network with two hidden layers with 64 and 32 nodes, then finally testing generalization ability.\n",
    "\n",
    "In every testing result, the VSN network performed well. It outshined a standard ANN with no hidden network, and also generalization ability. However, VSN faired slightly weaker when adding a deep hidden netowrk.\n",
    "\n",
    "This is just a mini test to see the merits and to test VSN network architecture.\n",
    "\n",
    "Ultimately, the tests are not concrete as I have not added any standard scaling or sorts which is standard for neural networks. And also the dataset is not only simple but not the type that needs a neural network, or to need and attention mechanism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
